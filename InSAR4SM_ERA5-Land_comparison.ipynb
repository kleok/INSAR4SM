{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------Import libraries --------------\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import datetime \n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#--------------------- INSAR4SM functionalities --------------\n",
    "from insar4sm.classes import INSAR4SM_stack, SM_point\n",
    "from insar4sm.gridding import WGS84_to_UTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cftime_to_datetime(cfdatetime):\n",
    "    '''\n",
    "    Time convertion functionality\n",
    "    '''\n",
    "    year=cfdatetime.year\n",
    "    month=cfdatetime.month\n",
    "    day=cfdatetime.day\n",
    "    hour=cfdatetime.hour\n",
    "    minute=cfdatetime.minute\n",
    "    second=cfdatetime.second\n",
    "    return datetime.datetime(year,month,day,hour,minute,second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ERA5_data (cell, ERA5_variables, ERA5_datasets):\n",
    "    \n",
    "    df_ERA5 = pd.DataFrame()\n",
    "    \n",
    "    for ERA5_dataset in ERA5_datasets:\n",
    "        df_dict={}\n",
    "\n",
    "        for ERA5_variable in ERA5_variables:\n",
    "            \n",
    "            if ERA5_variable in ['longitude',  'latitude']:\n",
    "                pass\n",
    "            elif ERA5_variable=='time':\n",
    "                time_var=ERA5_dataset.variables[ERA5_variable]\n",
    "                t_cal = ERA5_dataset.variables[ERA5_variable].calendar\n",
    "                dtime = netCDF4.num2date(time_var[:],time_var.units, calendar = t_cal)\n",
    "                dtime_datetime=[cftime_to_datetime(cfdatetime) for cfdatetime in dtime.data]\n",
    "                df_dict['Datetimes']=dtime_datetime\n",
    "                \n",
    "            elif ERA5_variable!='expver':\n",
    "                temp_name=ERA5_variable+'__'+ERA5_dataset[ERA5_variable].units\n",
    "                temp_dataset = ERA5_dataset[ERA5_variable][:][:,cell[0],cell[1]]\n",
    "                df_dict[temp_name]=np.squeeze(temp_dataset)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        # create a dataframe\n",
    "        df_ERA5_temp = pd.DataFrame(df_dict)\n",
    "        df_ERA5_temp.index = pd.to_datetime(df_ERA5_temp['Datetimes'])\n",
    "\n",
    "        # concatenate\n",
    "        df_ERA5 = pd.concat([df_ERA5, df_ERA5_temp])\n",
    "\n",
    "    return df_ERA5.sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case you want to reproduce the results of this notebook please download the folder SM_NA from http://147.102.106.42:5000/fsdownload/gxzvLswJM/public and replace the paths in the following cells.\n",
    "\n",
    "For example '/RSL02/SM_NA/era5/era5_land_na_orbit_100.nc' should become 'path_to_your_SM_NA/era5/era5_land_na_orbit_100.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM_AOI = '/RSL02/SM_NA/Plotting/bbox_aoi.geojson'\n",
    "ERA5_file_100 = '/RSL02/SM_NA/era5/era5_land_na_orbit_100.nc'\n",
    "ERA5_file_166 = '/RSL02/SM_NA/era5/era5_land_na_orbit_166.nc'\n",
    "ERA5_file_173 = '/RSL02/SM_NA/era5/era5_land_na_orbit_173.nc'\n",
    "\n",
    "InSAR4SM_100 = '/RSL02/SM_NA/INSAR4SM_results_100_sq250_FordDryLake/sm_inversions_INSAR4SM_results_100_sq250_FordDryLake_250.shp'\n",
    "InSAR4SM_173 = '/RSL02/SM_NA/INSAR4SM_results_173_sq250_FordDryLake/sm_inversions_INSAR4SM_results_173_sq250_FordDryLake_250.shp'\n",
    "InSAR4SM_166 = '/RSL02/SM_NA/INSAR4SM_results_166_sq250_FordDryLake/sm_inversions_INSAR4SM_estimations_166_sq250_250.shp'\n",
    "\n",
    "InSAR4SM_173_extend = '/RSL02/SM_NA/INSAR4SM_estimations_173_sq250_extent/sm_inversions_INSAR4SM_estimations_173_sq250_extent_250.shp'\n",
    "InSAR4SM_166_extend = '/RSL02/SM_NA/INSAR4SM_estimations_166_sq250_extent/sm_inversions_INSAR4SM_estimations_166_sq250_extent_250.shp'\n",
    "\n",
    "orbit_combs = [['173','14:00:00'],\n",
    "               ['100','14:00:00'],\n",
    "               ['166','02:00:00']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "InSAR4SM_100_df = gpd.read_file(InSAR4SM_100)\n",
    "InSAR4SM_173_df = gpd.read_file(InSAR4SM_173)\n",
    "InSAR4SM_166_df = gpd.read_file(InSAR4SM_166)\n",
    "InSAR4SM_173_extend_df = gpd.read_file(InSAR4SM_173_extend)\n",
    "InSAR4SM_166_extend_df = gpd.read_file(InSAR4SM_166_extend)\n",
    "\n",
    "InSAR4SM_173_df = pd.concat([InSAR4SM_173_df, InSAR4SM_173_extend_df])\n",
    "InSAR4SM_166_df = pd.concat([InSAR4SM_166_df, InSAR4SM_166_extend_df])\n",
    "\n",
    "SM_AOI_geom = gpd.read_file(SM_AOI)['geometry']\n",
    "SM_AOI_geom_bounds = gpd.read_file(SM_AOI)['geometry'].bounds\n",
    "\n",
    "ERA5_datasets = [netCDF4.Dataset(ERA5_file_166), netCDF4.Dataset(ERA5_file_173)]\n",
    "\n",
    "ERA5_data_temp=netCDF4.Dataset(ERA5_file_173)\n",
    "ERA5_variables = list(ERA5_data_temp.variables.keys())\n",
    "\n",
    "ERA5_lons = ERA5_data_temp.variables['longitude'][:].data\n",
    "ERA5_lats = ERA5_data_temp.variables['latitude'][:].data\n",
    "\n",
    "ERA_pixel_inds1 = np.logical_and(ERA5_lats > SM_AOI_geom_bounds['miny'].values,\n",
    "                                 ERA5_lats < SM_AOI_geom_bounds['maxy'].values)\n",
    "ERA_pixel_inds2 = np.logical_and(ERA5_lons > SM_AOI_geom_bounds['minx'].values,\n",
    "                                 ERA5_lons < SM_AOI_geom_bounds['maxx'].values)\n",
    "                                 \n",
    "cellinds1 =  np.where (ERA_pixel_inds1)[0]\n",
    "cellinds2 =  np.where (ERA_pixel_inds2)[0]\n",
    "cells = list(itertools.product(cellinds1, cellinds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-115.27 33.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # create a dataframe\n",
    "    df_ERA5 = get_ERA5_data (cell, ERA5_variables, ERA5_datasets)\n",
    "\n",
    "    lon_center = ERA5_data_temp.variables['longitude'][cell[1]].data\n",
    "    lat_center = ERA5_data_temp.variables['latitude'][cell[0]].data\n",
    "    print(lon_center, lat_center)\n",
    "    dist = 0.05\n",
    "    xmin = lon_center - dist\n",
    "    ymin = lat_center - dist\n",
    "    xmax = lon_center + dist\n",
    "    ymax = lat_center + dist\n",
    "    \n",
    "    InSAR4SM_100_df_cell = InSAR4SM_100_df.cx[xmin:xmax, ymin:ymax]\n",
    "    InSAR4SM_100_df_cell.drop(columns=['geometry'], inplace = True)\n",
    "    if len(InSAR4SM_100_df_cell) == 0:\n",
    "        InSAR4SM_100_df_cell_mean = pd.Series()\n",
    "    else:\n",
    "        InSAR4SM_100_df_cell = InSAR4SM_100_df_cell.dropna(axis = 0, how = 'all')\n",
    "        InSAR4SM_100_df_cell_mean = InSAR4SM_100_df_cell.mean()\n",
    "        InSAR4SM_100_df_cell_std = InSAR4SM_100_df_cell.std()\n",
    "        dates_100 = pd.to_datetime(InSAR4SM_100_df_cell.columns, exact=True, format = 'D%Y%m%d' )\n",
    "        datetimes_100 = [date_100+datetime.timedelta(hours = 14) for date_100 in dates_100]\n",
    "        InSAR4SM_100_df_cell_mean.index = datetimes_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "    InSAR4SM_173_df_cell = InSAR4SM_173_df.cx[xmin:xmax, ymin:ymax]\n",
    "    InSAR4SM_173_df_cell.drop(columns=['geometry'], inplace = True)\n",
    "    InSAR4SM_173_df_cell = InSAR4SM_173_df_cell.dropna(axis = 0, how = 'all')\n",
    "    InSAR4SM_173_df_cell_mean = InSAR4SM_173_df_cell.mean()\n",
    "    InSAR4SM_173_df_cell_std = InSAR4SM_173_df_cell.std()\n",
    "    dates_173 = pd.to_datetime(InSAR4SM_173_df_cell.columns, exact=True, format = 'D%Y%m%d' )\n",
    "    datetimes_173 = [date_173+datetime.timedelta(hours = 14) for date_173 in dates_173]\n",
    "    InSAR4SM_173_df_cell_mean.index = datetimes_173\n",
    "\n",
    "    InSAR4SM_166_df_cell = InSAR4SM_166_df.cx[xmin:xmax, ymin:ymax]\n",
    "    InSAR4SM_166_df_cell.drop(columns=['geometry'], inplace = True)\n",
    "    InSAR4SM_166_df_cell = InSAR4SM_166_df_cell.dropna(axis = 0, how = 'all')\n",
    "    InSAR4SM_166_df_cell_mean = InSAR4SM_166_df_cell.mean()\n",
    "    InSAR4SM_166_df_cell_std = InSAR4SM_166_df_cell.std()\n",
    "    dates_166 = pd.to_datetime(InSAR4SM_166_df_cell.columns, exact=True, format = 'D%Y%m%d' )\n",
    "    datetimes_166 = [date_166+datetime.timedelta(hours = 2) for date_166 in dates_166]\n",
    "    InSAR4SM_166_df_cell_mean.index = datetimes_166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InSAR4SM_df_cell_mean = pd.concat([InSAR4SM_100_df_cell_mean, InSAR4SM_173_df_cell_mean, InSAR4SM_166_df_cell_mean]).sort_index().to_frame()\n",
    "InSAR4SM_df_cell_mean.rename(columns={0:'InSAR4SM'}, inplace=True)\n",
    "InSAR4SM_df_cell_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # merge ERA5 observations with INSAR4SM estimations\n",
    "    InSAR4SM_df_cell_mean['ERA5'] = df_ERA5.loc[InSAR4SM_df_cell_mean.index]['swvl1__m**3 m**-3']*100\n",
    "    \n",
    "    InSAR4SM_df_cell_mean['orbit'] = 'S1_orbit_100'\n",
    "    InSAR4SM_df_cell_mean['orbit'].loc[datetimes_173]='S1_orbit_173'\n",
    "    InSAR4SM_df_cell_mean['orbit'].loc[datetimes_166]='S1_orbit_166'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = InSAR4SM_df_cell_mean['InSAR4SM'].values\n",
    "targets = InSAR4SM_df_cell_mean['ERA5'].values\n",
    "n = predictions.shape[0]\n",
    "rmse = np.linalg.norm(predictions - targets) / np.sqrt(n)\n",
    "corr, _ = pearsonr(predictions, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-07-04 14:00:00', '2018-07-10 02:00:00',\n",
       "               '2018-07-16 14:00:00', '2018-07-22 02:00:00',\n",
       "               '2018-07-28 14:00:00', '2018-08-03 02:00:00',\n",
       "               '2018-08-09 14:00:00', '2018-08-15 02:00:00',\n",
       "               '2018-08-21 14:00:00', '2018-09-02 14:00:00',\n",
       "               '2018-09-08 02:00:00', '2018-09-14 14:00:00',\n",
       "               '2018-09-20 02:00:00', '2018-09-26 14:00:00',\n",
       "               '2018-10-02 02:00:00', '2018-10-08 14:00:00',\n",
       "               '2018-10-14 02:00:00', '2018-10-20 14:00:00',\n",
       "               '2018-10-26 02:00:00', '2018-11-01 14:00:00',\n",
       "               '2018-11-07 02:00:00', '2018-11-13 14:00:00',\n",
       "               '2018-11-19 02:00:00', '2018-11-25 14:00:00',\n",
       "               '2018-12-01 02:00:00', '2018-12-07 14:00:00',\n",
       "               '2018-12-13 02:00:00', '2018-12-19 14:00:00',\n",
       "               '2018-12-25 02:00:00', '2018-12-31 14:00:00',\n",
       "               '2019-01-06 02:00:00', '2019-01-12 14:00:00',\n",
       "               '2019-01-18 02:00:00', '2019-01-24 14:00:00',\n",
       "               '2019-01-30 02:00:00', '2019-02-05 14:00:00',\n",
       "               '2019-02-11 02:00:00', '2019-02-17 14:00:00',\n",
       "               '2019-02-23 02:00:00', '2019-03-01 14:00:00',\n",
       "               '2019-03-07 02:00:00', '2019-03-13 14:00:00',\n",
       "               '2019-03-19 02:00:00', '2019-03-25 14:00:00',\n",
       "               '2019-03-31 02:00:00'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InSAR4SM_df_cell_mean['InSAR4SM'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-115.27 33.75\n",
      "Era5_cell_denoise_-115.27_33.75.svg\n",
      "-115.17 33.75\n",
      "Era5_cell_denoise_-115.17_33.75.svg\n",
      "-115.07 33.75\n",
      "Era5_cell_denoise_-115.07_33.75.svg\n",
      "-114.97 33.75\n",
      "Era5_cell_denoise_-114.97_33.75.svg\n",
      "-114.87 33.75\n",
      "Era5_cell_denoise_-114.87_33.75.svg\n",
      "-114.77 33.75\n",
      "Era5_cell_denoise_-114.77_33.75.svg\n",
      "-115.27 33.65\n",
      "Era5_cell_denoise_-115.27_33.65.svg\n",
      "-115.17 33.65\n",
      "Era5_cell_denoise_-115.17_33.65.svg\n",
      "-115.07 33.65\n",
      "Era5_cell_denoise_-115.07_33.65.svg\n",
      "-114.97 33.65\n",
      "Era5_cell_denoise_-114.97_33.65.svg\n",
      "-114.87 33.65\n",
      "Era5_cell_denoise_-114.87_33.65.svg\n",
      "-114.77 33.65\n",
      "Era5_cell_denoise_-114.77_33.65.svg\n",
      "-115.27 33.55\n",
      "Era5_cell_denoise_-115.27_33.55.svg\n",
      "-115.17 33.55\n",
      "Era5_cell_denoise_-115.17_33.55.svg\n",
      "-115.07 33.55\n",
      "Era5_cell_denoise_-115.07_33.55.svg\n",
      "-114.97 33.55\n",
      "Era5_cell_denoise_-114.97_33.55.svg\n",
      "-114.87 33.55\n",
      "Era5_cell_denoise_-114.87_33.55.svg\n",
      "-114.77 33.55\n",
      "Era5_cell_denoise_-114.77_33.55.svg\n"
     ]
    }
   ],
   "source": [
    "for cell in cells:\n",
    "           \n",
    "    # create a dataframe\n",
    "    df_ERA5 = get_ERA5_data (cell, ERA5_variables, ERA5_datasets)\n",
    "\n",
    "    lon_center = ERA5_data_temp.variables['longitude'][cell[1]].data\n",
    "    lat_center = ERA5_data_temp.variables['latitude'][cell[0]].data\n",
    "    print(lon_center, lat_center)\n",
    "    dist = 0.05\n",
    "    xmin = lon_center - dist\n",
    "    ymin = lat_center - dist\n",
    "    xmax = lon_center + dist\n",
    "    ymax = lat_center + dist\n",
    "    \n",
    "    InSAR4SM_100_df_cell = InSAR4SM_100_df.cx[xmin:xmax, ymin:ymax]\n",
    "    InSAR4SM_100_df_cell.drop(columns=['geometry'], inplace = True)\n",
    "    if len(InSAR4SM_100_df_cell) == 0:\n",
    "        InSAR4SM_100_df_cell_mean = pd.Series()\n",
    "    else:\n",
    "        InSAR4SM_100_df_cell = InSAR4SM_100_df_cell.dropna(axis = 0, how = 'all')\n",
    "        InSAR4SM_100_df_cell_mean = InSAR4SM_100_df_cell.mean()\n",
    "        InSAR4SM_100_df_cell_std = InSAR4SM_100_df_cell.std()\n",
    "        dates_100 = pd.to_datetime(InSAR4SM_100_df_cell.columns, exact=True, format = 'D%Y%m%d' )\n",
    "        datetimes_100 = [date_100+datetime.timedelta(hours = 14) for date_100 in dates_100]\n",
    "        InSAR4SM_100_df_cell_mean.index = datetimes_100\n",
    "    \n",
    "    InSAR4SM_173_df_cell = InSAR4SM_173_df.cx[xmin:xmax, ymin:ymax]\n",
    "    InSAR4SM_173_df_cell.drop(columns=['geometry'], inplace = True)\n",
    "    InSAR4SM_173_df_cell = InSAR4SM_173_df_cell.dropna(axis = 0, how = 'all')\n",
    "    InSAR4SM_173_df_cell_mean = InSAR4SM_173_df_cell.mean()\n",
    "    InSAR4SM_173_df_cell_std = InSAR4SM_173_df_cell.std()\n",
    "    dates_173 = pd.to_datetime(InSAR4SM_173_df_cell.columns, exact=True, format = 'D%Y%m%d' )\n",
    "    datetimes_173 = [date_173+datetime.timedelta(hours = 14) for date_173 in dates_173]\n",
    "    InSAR4SM_173_df_cell_mean.index = datetimes_173\n",
    "\n",
    "    InSAR4SM_166_df_cell = InSAR4SM_166_df.cx[xmin:xmax, ymin:ymax]\n",
    "    InSAR4SM_166_df_cell.drop(columns=['geometry'], inplace = True)\n",
    "    InSAR4SM_166_df_cell = InSAR4SM_166_df_cell.dropna(axis = 0, how = 'all')\n",
    "    InSAR4SM_166_df_cell_mean = InSAR4SM_166_df_cell.mean()\n",
    "    InSAR4SM_166_df_cell_std = InSAR4SM_166_df_cell.std()\n",
    "    dates_166 = pd.to_datetime(InSAR4SM_166_df_cell.columns, exact=True, format = 'D%Y%m%d' )\n",
    "    datetimes_166 = [date_166+datetime.timedelta(hours = 2) for date_166 in dates_166]\n",
    "    InSAR4SM_166_df_cell_mean.index = datetimes_166\n",
    "\n",
    "    InSAR4SM_df_cell_mean = pd.concat([InSAR4SM_100_df_cell_mean, InSAR4SM_173_df_cell_mean, InSAR4SM_166_df_cell_mean]).sort_index().to_frame()\n",
    "    InSAR4SM_df_cell_mean.rename(columns={0:'InSAR4SM'}, inplace=True)\n",
    "    \n",
    "    # merge ERA5 observations with INSAR4SM estimations\n",
    "    InSAR4SM_df_cell_mean['ERA5'] = df_ERA5.loc[InSAR4SM_df_cell_mean.index]['swvl1__m**3 m**-3']*100\n",
    "    \n",
    "    InSAR4SM_df_cell_mean['orbit'] = 'S1_orbit_100'\n",
    "    InSAR4SM_df_cell_mean['orbit'].loc[datetimes_173]='S1_orbit_173'\n",
    "    InSAR4SM_df_cell_mean['orbit'].loc[datetimes_166]='S1_orbit_166'\n",
    "    \n",
    "    predictions = InSAR4SM_df_cell_mean['InSAR4SM'].values\n",
    "    targets = InSAR4SM_df_cell_mean['ERA5'].values\n",
    "    n = predictions.shape[0]\n",
    "    rmse = np.linalg.norm(predictions - targets) / np.sqrt(n)\n",
    "    corr, _ = pearsonr(predictions, targets)\n",
    "\n",
    "    if pd.to_datetime('2018-10-03T14:00:00') in InSAR4SM_df_cell_mean['InSAR4SM'].index:\n",
    "        predictions_denoise = InSAR4SM_df_cell_mean['InSAR4SM'].drop([pd.to_datetime('2018-10-03T14:00:00')])\n",
    "        targets_denoise = InSAR4SM_df_cell_mean['ERA5'].drop([pd.to_datetime('2018-10-03T14:00:00.00')])\n",
    "        n = predictions_denoise.shape[0]\n",
    "        rmse = np.linalg.norm(predictions_denoise - targets_denoise) / np.sqrt(n)\n",
    "        corr, _ = pearsonr(predictions_denoise, targets_denoise)\n",
    "\n",
    "    elif pd.to_datetime('2018-10-02 02:00:00') in InSAR4SM_df_cell_mean['InSAR4SM'].index:\n",
    "        predictions_denoise = InSAR4SM_df_cell_mean['InSAR4SM'].drop([pd.to_datetime('2018-10-02 02:00:00')])\n",
    "        targets_denoise = InSAR4SM_df_cell_mean['ERA5'].drop([pd.to_datetime('2018-10-02 02:00:00')])\n",
    "        n = predictions_denoise.shape[0]\n",
    "        rmse = np.linalg.norm(predictions_denoise - targets_denoise) / np.sqrt(n)\n",
    "        corr, _ = pearsonr(predictions_denoise, targets_denoise)\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    fig = plt.figure(figsize=(1.7,2))\n",
    "\n",
    "    ax = InSAR4SM_df_cell_mean['ERA5'].plot(style='s', c='k', alpha=0.6, ms=3)\n",
    "    ax = sns.scatterplot(x=InSAR4SM_df_cell_mean.index,\n",
    "                    y='InSAR4SM',\n",
    "                    hue='orbit',\n",
    "                    data=InSAR4SM_df_cell_mean,\n",
    "                    size=2,\n",
    "                    alpha=0.7)\n",
    "    ax.set(ylim=(0, 25))\n",
    "    ax.get_legend().remove()\n",
    "    ax.annotate(\" RMSE:{0:.1f} $m^3/m^3$ \\n R:{1:.2f} \".format(rmse, corr), xy=(0.,0.7), xycoords='axes fraction',fontsize=8)\n",
    "\n",
    "    ax.yaxis.label.set_visible(False)\n",
    "    \n",
    "    export_name = 'Era5_cell_denoise_{0:.2f}_{1:.2f}.svg'.format(np.round(lon_center,2),np.round(lat_center,2))\n",
    "    print(export_name)\n",
    "    plt.savefig('/RSL02/SM_NA/revisions_r2_figures/era5_plots/r2_{}'.format(export_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
